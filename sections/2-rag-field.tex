\section{Retrieval Augmented Generation}

This section will give an overview of the research field of Retrieval Augmented Generation (RAG), with a focus on its inception and key contributions leading up to the G-Retriever paper.

RAG is a subfield of Natural Language Processing that has gained significant traction since its inception in 2020.
It combines the strengths of retrieval-based and generation-based models, aiming to improve the quality of generated text by incorporating information from retrieved documents.

The foundational work in this field was done by \cite{rag}, who introduced the RAG framework.
The main idea behind this paper was to allow pre-trained language models to access external knowledge sources during generation, thereby allowing the model to condition on information retrieved from external sources, in addition to  the knowledge embedded into its weight during the training process.
The authors show that such external knowledge sources can be updated, expanded, and refined independently of the model, which allows for more up-to-date and diverse information without the need to expend the resources associated with training large language models.


The core idea is quite simple: Knowledge relevant to the query is retrieved by some retrieval component and then made available during the generation step, either by simply prepending the data to the query, or via more involved mechanisms, that might allow the entire system or parts of it to be trained end-to-end \cite{in-context}.

Because this approach works well for knowledge-intensive tasks, a common use case for RAG models is question answering.
Depending on the intended application, there are different conceivable knowledge sources.
Common choices include Wikipedia articles or scientific papers.
Some papers also make use of the internet as a knowledge source, which allows for more up-to-date information, but also introduces the risk of noise and misinformation.
This offers the opportunity to build on the immense effort that has already gone into optimizing search engines such as Bing or Google, instead of having to build or train a custom retrieval component.
Otherwise, similarity of vector embeddings is a popular choice to determine relevance of documents.

One important choice is the number of documents that are retrieved, with typical choices being 3-5 documents per query.
Some approaches perform the retrieval step only once per query, conditioning the entire output on the same set of documents. Others retrieve documents more often, in the extreme once per generated token.
