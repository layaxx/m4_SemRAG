\section{G-Retriever}

This section introduces the 2024 G-Retriever model, outlining its motivation, architecture, and evaluation results.
In the following section, G-Retriever is compared to other retrieval-augmented models to highlight key differences

\subsection{Motivation}
G-Retriever applies the RAG approach to text-based graphs.
Introduced in 2024 by \cite{g-retriever}, it is designed for question-answering tasks using text-based graphs \textemdash{} i.e., graphs in which both nodes and edges are associated with textual labels \textemdash{} as knowledge sources. Such graphs are prevalent in various domains, including knowledge graphs, recommendation systems, and scene graphs, the authors argue.

Given that these graphs, particularly knowledge graphs, can be large and contain only a subset of nodes and edges relevant to a specific task, G-Retriever aims to retrieve the most relevant subgraph for each generation task.
This approach enhances generation efficiency, reduces the required context window length, and improves the quality of generated text by focusing on the most relevant information.

\subsection{Architecture}

The G-Retriever process consists of four key steps: (1) indexing, (2) retrieval, (3) subgraph construction, and (4) generation.

\paragraph{(1) Indexing} Node and edge attributes are converted into vector representations using a pre-trained language model, such as SentenceBERT. The resulting vectors are stored in a nearest-neighbor data structure to facilitate efficient retrieval.

\paragraph{(2) Retrieval} The query is encoded using the same pre-trained language model, and the top-k most relevant nodes and edges are retrieved based on embedding similarity.
The value of k varies for nodes and edges (3 and 5, respectively, in the authors' experiments, with these values shown to yield optimal results).
Previous approaches would directly use the retrieved results as model input, but the authors argue that this is suboptimal, as the most relevant nodes and edges may not be interconnected in the original graph, potentially omitting relevant relationships.
To address this, they introduce a subgraph construction step to preserve the structural advantages of graphs over unstructured text.



\paragraph{(3) Subgraph Construction} The retrieved nodes and edges are used to form a subgraph that maximizes relevant information while minimizing the inclusion of unnecessary nodes and edges.
This is achieved using a modified version of the Prize-Collecting Steiner Tree (PCST) algorithm.

PCST is a well-known optimization problem in graph theory, where the objective is to find a prize-maximizing and cost-minimizing subgraph that connects a set of nodes.
In its standard form, PCST assumes that all valuable information resides in nodes, with edges serving solely as connections.
However, in the case of text-based graphs, edges can also contain meaningful textual attributes.
To accommodate this, the authors modify PCST to assign both prizes and costs to edges.
If an edge's prize is less than or equal to its cost, it is treated as a reduced-cost edge.
If an edge's prize exceeds its cost, a virtual node is introduced to connect the original nodes. The prize of this node is set to the difference between the prize and cost of the original edge. The new edges introduced by this transformation are assigned a cost of zero.

By adapting PCST in this manner, the same optimization algorithm can be applied while preserving valuable edge information.

\paragraph{(4) Generation} Once the optimal subgraph has been constructed, it is passed to the generative model. The subgraph is incorporated in two ways:

\begin{enumerate}
    \item \textbf{Graph Encoding:} The subgraph is processed using a graph encoder, projected to the appropriate dimension via a projection layer, and supplied to the LLM for generation.
    \item \textbf{Textual Representation:} The subgraph is converted into a structured text format (similar to CSV) and prepended to the query.
\end{enumerate}

The first approach enables soft prompt tuning, while the second provides explicit context to the model.
The authors note that although their chosen textual representation may not be optimal, it performs well in practice.
An ablation study confirms that both encoded and textualized graphs contribute significantly to performance, with the projection layer having the least impact, serving primarily to align dimensions between the graph encoder and LLM.

\subsection{Evaluation and Results}

The authors evaluate G-Retriever on a dataset of text-based graphs, queries, and expected answers.
This dataset is created by converting existing benchmarks \textemdash{} ExplaGraphs (debate stance prediction, \cite{explagraphs}), SceneGraphs (visual question answering, \cite{scenegraphs}), and WebQSP (large-scale knowledge graphs, \cite{webqsp}) \textemdash{} into a unified format.

The dataset represents three distinct evaluation scenarios:

\begin{itemize}

    \item Common sense reasoning: Determining whether common sense related arguments support or refute each other (evaluated using accuracy).
    \item Scene Graph Question Answering: Answering open-ended questions about spatial relationships within a scene graph (evaluated using accuracy).
    \item Knowledge based Question Answering: Answering queries based on a knowledge graph, potentially requiring multi-hop reasoning (evaluated using Hit@1).
\end{itemize}

The results demonstrate that G-Retriever outperforms baseline models across all three scenarios. The baselines include LLMs that receive no additional information, the entire graph as input, or the top-k retrieved nodes and edges without subgraph construction.

Additionally, the authors show that each component of G-Retriever contributes to its performance.
Notably, G-Retriever exhibits reduced hallucination rates compared to the baselines, as evaluated in spot checks.

A particularly interesting aspect of G-Retriever is explainability: Since the model generates answers based on a well-defined subgraph, the reasoning process can be easily fact-checked by inspecting the nodes and edges involved.
However, this aspect is not evaluated further in the paper.